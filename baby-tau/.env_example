# .env

# --- Port Configuration ---
# Note: With network_mode: host, these are the HOST ports the services will listen on.
# Ensure they are unique and available on your Jetson.
SPEACHES_HOST_PORT=8001
VLLM_PORT=8000
KOKORO_TTS_HOST_PORT=8880

# --- Image Tags ---
# Use the specific tags for your Jetpack/CUDA version (r36.4.0 / cu128 in this case)
SPEACHES_TAG=dustynv/speaches:r36.4.0-cu128-24.04
#SPEACHES_TAG=speaches-test:r36.4.3
KOKORO_TTS_TAG=dustynv/kokoro-tts:fastapi-r36.4.0-cu128-24.04
VLLM_TAG=dustynv/vllm:0.7.4-r36.4.0-cu128-24.04
# Assuming 'python-3.12:r36.4.3' is an image you have built or pulled from the jetson-containers setup
#PYTHON_IMAGE=torchaudio:2.6.0-r36.4.0-cu128-24.04
#PYTHON_TAG=silerovad:r36.4.3
PYTHON_TAG=sound-utils:r36.4.3-cu1280
# --- VLLM Configuration ---
# Default model to load (can be overridden)
#VLLM_MODEL=google/gemma-3-1b-it
#VLLM_MODEL=mistralai/Mistral-Small-3.1-24B-Instruct-2503
VLLM_MODEL=ibm-granite/granite-3.1-8b-instruct
OLLAMA_MODEL=llama-3.2:1b
#OLLAMA_MODEL=llama-3.2:3b

# Hugging Face Hub Token (required for gated models like Gemma, Llama)
# Replace with your actual token: https://huggingface.co/settings/tokens
HF_TOKEN=
# GPU memory utilization limit (0.0 to 1.0)
VLLM_GPU_MEMORY_UTILIZATION=0.30

TTS_VOICE=af_alloy

# Add VAD_EVERY_N_CHUNKS to control how often VAD is processed
VAD_EVERY_N_CHUNKS=6

# --- Optional: Specify devices ---
# Set specific GPU if needed, otherwise 'all' is fine for single GPU Jetson
# NVIDIA_VISIBLE_DEVICES=0