2025-04-20 20:16:42,556 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:16:42,703 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:16:47,241 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:16:47,241 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:16:47,242 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:16:47,242 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:16:47,242 - api_adapter_responses - INFO - =======================
2025-04-20 20:16:47,242 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:16:47,242 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:16:47,243 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:16:47,243 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:16:47,243 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:16:52,008 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:16:52,009 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:16:52,009 - api_adapter_stream - INFO - Processing streaming response from chat.completions API
2025-04-20 20:16:56,373 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:16:56,373 - api_adapter_stream - INFO - Response completed with text:  Applying patch to "example.py"...

`apply_patch`, {"cmd":["apply_patch","*** Begin Patch\n*** Updat...
2025-04-20 20:16:56,374 - api_adapter_stream - INFO - Received [DONE] message after 159 chunks
2025-04-20 20:23:15,433 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:23:15,584 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:23:18,765 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:23:18,765 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:23:18,766 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:23:18,766 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:23:18,766 - api_adapter_responses - INFO - =======================
2025-04-20 20:23:18,766 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:23:18,766 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:23:18,766 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:23:18,766 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:23:18,766 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:23:23,540 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:23:23,540 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:23:23,541 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_41e43f9278af40c7b9eaac44a2e99a50; message_id msg_cfd8bfaefd6745deab9db2e0bb2e1af7
2025-04-20 20:23:29,801 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:23:29,801 - api_adapter_stream - INFO - Response completed with text: To initiate the patch application process, I will emit the `apply_patch` command. Here's an example ...
2025-04-20 20:23:29,802 - api_adapter_stream - INFO - Received [DONE] message after 225 chunks
2025-04-20 20:26:26,461 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:26:26,611 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:26:39,440 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:26:39,440 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:26:39,441 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:26:39,441 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:26:39,441 - api_adapter_responses - INFO - =======================
2025-04-20 20:26:39,441 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:26:39,441 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:26:39,441 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:26:39,442 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:26:39,442 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:26:39,628 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:26:39,628 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:26:39,628 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_e187630e07364f9689d35362b83699cc; message_id msg_20206743611546838b0ff8da9f9d9749
2025-04-20 20:26:39,629 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_e187630e07364f9689d35362b83699cc', object='response', created_at=1745180799, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:26:39,630 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_e187630e07364f9689d35362b83699cc', object='response', created_at=1745180799, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:26:44,135 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:26:44,136 - api_adapter_stream - INFO - Response completed with text: Here's an `apply_patch` command to modify a file:

```bash
{"cmd":["apply_patch","*** Begin Patch\n*...
2025-04-20 20:26:44,136 - api_adapter_stream - INFO - Received [DONE] message after 165 chunks
2025-04-20 20:28:25,433 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:28:25,582 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:28:28,962 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:28:28,962 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:28:28,962 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:28:28,963 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:28:28,963 - api_adapter_responses - INFO - =======================
2025-04-20 20:28:28,963 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:28:28,963 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:28:28,964 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:28:28,964 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:28:28,964 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:28:29,175 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:28:29,175 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:28:29,176 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_132d1eed11cc44e08979c1892b0a33de; message_id msg_dbca7c6b7c4445bfb125de378fd768e2
2025-04-20 20:28:29,176 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_132d1eed11cc44e08979c1892b0a33de', object='response', created_at=1745180909, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:28:29,177 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_132d1eed11cc44e08979c1892b0a33de', object='response', created_at=1745180909, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:28:29,179 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'Apply'}, 'finish_reason': None}]}
2025-04-20 20:28:29,228 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:28:29,284 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\n'}, 'finish_reason': None}]}
2025-04-20 20:28:29,335 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '{"'}, 'finish_reason': None}]}
2025-04-20 20:28:29,384 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'cmd'}, 'finish_reason': None}]}
2025-04-20 20:28:29,435 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '":'}, 'finish_reason': None}]}
2025-04-20 20:28:29,491 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' ["'}, 'finish_reason': None}]}
2025-04-20 20:28:29,547 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:28:29,602 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:28:29,652 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '",'}, 'finish_reason': None}]}
2025-04-20 20:28:29,703 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' "***'}, 'finish_reason': None}]}
2025-04-20 20:28:29,757 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Begin'}, 'finish_reason': None}]}
2025-04-20 20:28:29,809 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:28:29,861 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:28:29,914 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:28:29,968 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180909, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Update'}, 'finish_reason': None}]}
2025-04-20 20:28:30,018 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' File'}, 'finish_reason': None}]}
2025-04-20 20:28:30,074 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':'}, 'finish_reason': None}]}
2025-04-20 20:28:30,127 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' app'}, 'finish_reason': None}]}
2025-04-20 20:28:30,180 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.js'}, 'finish_reason': None}]}
2025-04-20 20:28:30,235 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:28:30,286 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@@'}, 'finish_reason': None}]}
2025-04-20 20:28:30,337 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:28:30,392 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '10'}, 'finish_reason': None}]}
2025-04-20 20:28:30,446 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:28:30,503 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '6'}, 'finish_reason': None}]}
2025-04-20 20:28:30,556 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' +'}, 'finish_reason': None}]}
2025-04-20 20:28:30,611 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '10'}, 'finish_reason': None}]}
2025-04-20 20:28:30,677 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:28:30,737 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '7'}, 'finish_reason': None}]}
2025-04-20 20:28:30,793 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' @'}, 'finish_reason': None}]}
2025-04-20 20:28:30,851 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@"'}, 'finish_reason': None}]}
2025-04-20 20:28:30,910 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ']}'}, 'finish_reason': None}]}
2025-04-20 20:28:30,961 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-69', 'object': 'chat.completion.chunk', 'created': 1745180910, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'stop'}]}
2025-04-20 20:28:30,962 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:28:30,962 - api_adapter_stream - INFO - Response completed with text: Apply Patch:
{"cmd": ["apply_patch", "*** Begin Patch\n*** Update File: app.js\n@@ -10,6 +10,7 @@"]}...
2025-04-20 20:28:30,962 - api_adapter_stream - INFO - Received [DONE] message after 69 chunks
2025-04-20 20:30:18,600 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:30:18,750 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:31:08,096 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:31:08,244 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:31:10,788 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:31:10,789 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:31:10,789 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:31:10,789 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:31:10,789 - api_adapter_responses - INFO - =======================
2025-04-20 20:31:10,790 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:31:10,790 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:31:10,790 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:31:10,790 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:31:10,790 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:31:10,802 - api_adapter_responses - INFO - {'model': 'llama3.2:latest', 'temperature': 1.0, 'top_p': 1.0, 'stream': True, 'system': 'You are operating as and within the Codex CLI, a terminal-based agentic coding assistant built by OpenAI. It wraps OpenAI models to enable natural language interaction with a local codebase. You are expected to be precise, safe, and helpful.\n\nYou can:\n- Receive user prompts, project context, and files.\n- Stream responses and emit function calls (e.g., shell commands, code edits).\n- Apply patches, run commands, and manage user approvals based on policy.\n- Work inside a sandboxed, git-backed workspace with rollback support.\n- Log telemetry so sessions can be replayed or inspected later.\n- More details on your functionality are available at `codex --help`\n\nThe Codex CLI is open-sourced. Don\'t confuse yourself with the old Codex language model built by OpenAI many moons ago (this is understandably top of mind for you!). Within this context, Codex refers to the open-source agentic coding interface.\n\nYou are an agent - please keep going until the user\'s query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. If you are not sure about file content or codebase structure pertaining to the user\'s request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.\n\nPlease resolve the user\'s task by editing and testing the code files in your current code execution session. You are a deployed coding agent. Your session allows for you to modify and run code. The repo(s) are already cloned in your working directory, and you must fully solve the problem for your answer to be considered correct.\n\nYou MUST adhere to the following criteria when executing the task:\n- Working on the repo(s) in the current environment is allowed, even if they are proprietary.\n- Analyzing code for vulnerabilities is allowed.\n- Showing user code and tool call details is allowed.\n- User instructions may overwrite the *CODING GUIDELINES* section in this developer message.\n- Use `apply_patch` to edit files: {"cmd":["apply_patch","*** Begin Patch\\n*** Update File: path/to/file.py\\n@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch"]}\n- If completing the user\'s task requires writing or modifying files:\n    - Your code and final answer should follow these *CODING GUIDELINES*:\n        - Fix the problem at the root cause rather than applying surface-level patches, when possible.\n        - Avoid unneeded complexity in your solution.\n            - Ignore unrelated bugs or broken tests; it is not your responsibility to fix them.\n        - Update documentation as necessary.\n        - Keep changes consistent with the style of the existing codebase. Changes should be minimal and focused on the task.\n            - Use `git log` and `git blame` to search the history of the codebase if additional context is required; internet access is disabled.\n        - NEVER add copyright or license headers unless specifically requested.\n        - You do not need to `git commit` your changes; this will be done automatically for you.\n        - If there is a .pre-commit-config.yaml, use `pre-commit run --files ...` to check that your changes pass the pre-commit checks. However, do not fix pre-existing errors on lines you didn\'t touch.\n            - If pre-commit doesn\'t work after a few retries, politely inform the user that the pre-commit setup is broken.\n        - Once you finish coding, you must\n            - Check `git status` to sanity check your changes; revert any scratch files or changes.\n            - Remove all inline comments you added as much as possible, even if they look normal. Check using `git diff`. Inline comments must be generally avoided, unless active maintainers of the repo, after long careful study of the code and the issue, will still misinterpret the code without the comments.\n            - Check if you accidentally add copyright or license headers. If so, remove them.\n            - Try to run pre-commit if it is available.\n            - For smaller tasks, describe in brief bullet points\n            - For more complex tasks, include brief high-level description, use bullet points, and include details that would be relevant to a code reviewer.\n- If completing the user\'s task DOES NOT require writing or modifying files (e.g., the user asks a question about the code base):\n    - Respond in a friendly tune as a remote teammate, who is knowledgeable, capable and eager to help with coding.\n- When your task involves writing or modifying files:\n    - Do NOT tell the user to "save the file" or "copy the code into a file" if you already created or modified the file using `apply_patch`. Instead, reference the file as already saved.\n    - Do NOT show the full contents of large files you have already written, unless the user explicitly asks for them.\n# Codex Custom Instructions\n\n- Always explain what changes you\'re making and why\n- Prefer to use modern JavaScript/TypeScript practices\n- Work with the existing architecture of the codebase\n- When writing code, prioritize readability and maintainability \n- Use Git for version control operations when appropriate\n- When accessing the API, use the adapter at http://localhost:8080\n', 'messages': [{'role': 'system', 'content': 'You are operating as and within the Codex CLI, a terminal-based agentic coding assistant built by OpenAI. It wraps OpenAI models to enable natural language interaction with a local codebase. You are expected to be precise, safe, and helpful.\n\nYou can:\n- Receive user prompts, project context, and files.\n- Stream responses and emit function calls (e.g., shell commands, code edits).\n- Apply patches, run commands, and manage user approvals based on policy.\n- Work inside a sandboxed, git-backed workspace with rollback support.\n- Log telemetry so sessions can be replayed or inspected later.\n- More details on your functionality are available at `codex --help`\n\nThe Codex CLI is open-sourced. Don\'t confuse yourself with the old Codex language model built by OpenAI many moons ago (this is understandably top of mind for you!). Within this context, Codex refers to the open-source agentic coding interface.\n\nYou are an agent - please keep going until the user\'s query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. If you are not sure about file content or codebase structure pertaining to the user\'s request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.\n\nPlease resolve the user\'s task by editing and testing the code files in your current code execution session. You are a deployed coding agent. Your session allows for you to modify and run code. The repo(s) are already cloned in your working directory, and you must fully solve the problem for your answer to be considered correct.\n\nYou MUST adhere to the following criteria when executing the task:\n- Working on the repo(s) in the current environment is allowed, even if they are proprietary.\n- Analyzing code for vulnerabilities is allowed.\n- Showing user code and tool call details is allowed.\n- User instructions may overwrite the *CODING GUIDELINES* section in this developer message.\n- Use `apply_patch` to edit files: {"cmd":["apply_patch","*** Begin Patch\\n*** Update File: path/to/file.py\\n@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch"]}\n- If completing the user\'s task requires writing or modifying files:\n    - Your code and final answer should follow these *CODING GUIDELINES*:\n        - Fix the problem at the root cause rather than applying surface-level patches, when possible.\n        - Avoid unneeded complexity in your solution.\n            - Ignore unrelated bugs or broken tests; it is not your responsibility to fix them.\n        - Update documentation as necessary.\n        - Keep changes consistent with the style of the existing codebase. Changes should be minimal and focused on the task.\n            - Use `git log` and `git blame` to search the history of the codebase if additional context is required; internet access is disabled.\n        - NEVER add copyright or license headers unless specifically requested.\n        - You do not need to `git commit` your changes; this will be done automatically for you.\n        - If there is a .pre-commit-config.yaml, use `pre-commit run --files ...` to check that your changes pass the pre-commit checks. However, do not fix pre-existing errors on lines you didn\'t touch.\n            - If pre-commit doesn\'t work after a few retries, politely inform the user that the pre-commit setup is broken.\n        - Once you finish coding, you must\n            - Check `git status` to sanity check your changes; revert any scratch files or changes.\n            - Remove all inline comments you added as much as possible, even if they look normal. Check using `git diff`. Inline comments must be generally avoided, unless active maintainers of the repo, after long careful study of the code and the issue, will still misinterpret the code without the comments.\n            - Check if you accidentally add copyright or license headers. If so, remove them.\n            - Try to run pre-commit if it is available.\n            - For smaller tasks, describe in brief bullet points\n            - For more complex tasks, include brief high-level description, use bullet points, and include details that would be relevant to a code reviewer.\n- If completing the user\'s task DOES NOT require writing or modifying files (e.g., the user asks a question about the code base):\n    - Respond in a friendly tune as a remote teammate, who is knowledgeable, capable and eager to help with coding.\n- When your task involves writing or modifying files:\n    - Do NOT tell the user to "save the file" or "copy the code into a file" if you already created or modified the file using `apply_patch`. Instead, reference the file as already saved.\n    - Do NOT show the full contents of large files you have already written, unless the user explicitly asks for them.\n# Codex Custom Instructions\n\n- Always explain what changes you\'re making and why\n- Prefer to use modern JavaScript/TypeScript practices\n- Work with the existing architecture of the codebase\n- When writing code, prioritize readability and maintainability \n- Use Git for version control operations when appropriate\n- When accessing the API, use the adapter at http://localhost:8080\n'}, {'role': 'user', 'content': 'this is a test, just call apply patch with some text and filename'}], 'tools': []}
2025-04-20 20:31:11,018 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:31:11,019 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:31:11,019 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_ecb36b70963742b384e5501c7a1e3684; message_id msg_ca256e6e86f34bd29ccd15c1696950e0
2025-04-20 20:31:11,020 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_ecb36b70963742b384e5501c7a1e3684', object='response', created_at=1745181071, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:31:11,021 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_ecb36b70963742b384e5501c7a1e3684', object='response', created_at=1745181071, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:31:11,022 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '`'}, 'finish_reason': None}]}
2025-04-20 20:31:11,072 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:31:11,132 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:31:11,175 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '`'}, 'finish_reason': None}]}
2025-04-20 20:31:11,231 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' {"'}, 'finish_reason': None}]}
2025-04-20 20:31:11,295 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'cmd'}, 'finish_reason': None}]}
2025-04-20 20:31:11,365 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '":["'}, 'finish_reason': None}]}
2025-04-20 20:31:11,424 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:31:11,490 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:31:11,549 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '","'}, 'finish_reason': None}]}
2025-04-20 20:31:11,606 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:31:11,661 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Begin'}, 'finish_reason': None}]}
2025-04-20 20:31:11,722 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:31:11,785 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:31:11,842 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:31:11,898 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Update'}, 'finish_reason': None}]}
2025-04-20 20:31:11,958 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181071, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' File'}, 'finish_reason': None}]}
2025-04-20 20:31:12,013 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':'}, 'finish_reason': None}]}
2025-04-20 20:31:12,074 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' src'}, 'finish_reason': None}]}
2025-04-20 20:31:12,132 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '/main'}, 'finish_reason': None}]}
2025-04-20 20:31:12,192 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.py'}, 'finish_reason': None}]}
2025-04-20 20:31:12,250 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:31:12,309 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@@'}, 'finish_reason': None}]}
2025-04-20 20:31:12,367 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:31:12,423 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '15'}, 'finish_reason': None}]}
2025-04-20 20:31:12,477 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:31:12,536 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '6'}, 'finish_reason': None}]}
2025-04-20 20:31:12,594 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' +'}, 'finish_reason': None}]}
2025-04-20 20:31:12,649 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '15'}, 'finish_reason': None}]}
2025-04-20 20:31:12,698 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:31:12,753 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '7'}, 'finish_reason': None}]}
2025-04-20 20:31:12,812 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' @'}, 'finish_reason': None}]}
2025-04-20 20:31:12,866 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@'}, 'finish_reason': None}]}
2025-04-20 20:31:12,923 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:31:12,981 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181072, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'def'}, 'finish_reason': None}]}
2025-04-20 20:31:13,036 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' add'}, 'finish_reason': None}]}
2025-04-20 20:31:13,092 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '(x'}, 'finish_reason': None}]}
2025-04-20 20:31:13,147 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ',y'}, 'finish_reason': None}]}
2025-04-20 20:31:13,202 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '):'}, 'finish_reason': None}]}
2025-04-20 20:31:13,257 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-\\'}, 'finish_reason': None}]}
2025-04-20 20:31:13,323 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:31:13,383 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:31:13,439 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:31:13,497 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' x'}, 'finish_reason': None}]}
2025-04-20 20:31:13,547 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+y'}, 'finish_reason': None}]}
2025-04-20 20:31:13,603 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:31:13,657 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+\\'}, 'finish_reason': None}]}
2025-04-20 20:31:13,714 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'ndef'}, 'finish_reason': None}]}
2025-04-20 20:31:13,769 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' add'}, 'finish_reason': None}]}
2025-04-20 20:31:13,825 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '(x'}, 'finish_reason': None}]}
2025-04-20 20:31:13,879 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ',y'}, 'finish_reason': None}]}
2025-04-20 20:31:13,934 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '):\\'}, 'finish_reason': None}]}
2025-04-20 20:31:13,993 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181073, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:31:14,047 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:31:14,102 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' if'}, 'finish_reason': None}]}
2025-04-20 20:31:14,159 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' x'}, 'finish_reason': None}]}
2025-04-20 20:31:14,214 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '<y'}, 'finish_reason': None}]}
2025-04-20 20:31:14,273 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\\'}, 'finish_reason': None}]}
2025-04-20 20:31:14,331 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:31:14,392 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '   '}, 'finish_reason': None}]}
2025-04-20 20:31:14,447 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:31:14,504 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' x'}, 'finish_reason': None}]}
2025-04-20 20:31:14,560 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+y'}, 'finish_reason': None}]}
2025-04-20 20:31:14,616 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:31:14,675 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:31:14,732 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' else'}, 'finish_reason': None}]}
2025-04-20 20:31:14,788 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\\'}, 'finish_reason': None}]}
2025-04-20 20:31:14,842 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:31:14,898 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '   '}, 'finish_reason': None}]}
2025-04-20 20:31:14,958 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181074, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:31:15,015 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181075, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' x'}, 'finish_reason': None}]}
2025-04-20 20:31:15,074 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181075, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-y'}, 'finish_reason': None}]}
2025-04-20 20:31:15,133 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181075, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:31:15,187 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181075, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '"}'}, 'finish_reason': None}]}
2025-04-20 20:31:15,242 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-617', 'object': 'chat.completion.chunk', 'created': 1745181075, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'stop'}]}
2025-04-20 20:31:15,243 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:31:15,243 - api_adapter_stream - INFO - Response completed with text: `apply_patch` {"cmd":["apply_patch","*** Begin Patch\n*** Update File: src/main.py\n@@ -15,6 +15,7 @...
2025-04-20 20:31:15,244 - api_adapter_stream - INFO - Received [DONE] message after 151 chunks
2025-04-20 20:32:03,467 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:32:03,617 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:32:09,521 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:32:09,668 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:32:09,798 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:32:09,798 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:32:09,798 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:32:09,798 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:32:09,798 - api_adapter_responses - INFO - =======================
2025-04-20 20:32:09,799 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:32:09,799 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:32:09,799 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:32:09,799 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:32:09,799 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:32:09,805 - api_adapter_responses - INFO - []
2025-04-20 20:32:09,987 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:32:09,987 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:32:09,988 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_57e229e634de46dd84669748c59a4f64; message_id msg_79031ce790db49c2bb37d707543edc9f
2025-04-20 20:32:09,988 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_57e229e634de46dd84669748c59a4f64', object='response', created_at=1745181129, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:32:09,989 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_57e229e634de46dd84669748c59a4f64', object='response', created_at=1745181129, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:32:09,990 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181129, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '{'}, 'finish_reason': None}]}
2025-04-20 20:32:10,050 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' "'}, 'finish_reason': None}]}
2025-04-20 20:32:10,107 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'cmd'}, 'finish_reason': None}]}
2025-04-20 20:32:10,164 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '":'}, 'finish_reason': None}]}
2025-04-20 20:32:10,223 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' ["'}, 'finish_reason': None}]}
2025-04-20 20:32:10,282 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:32:10,348 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:32:10,404 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '",'}, 'finish_reason': None}]}
2025-04-20 20:32:10,469 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' "***'}, 'finish_reason': None}]}
2025-04-20 20:32:10,522 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Begin'}, 'finish_reason': None}]}
2025-04-20 20:32:10,580 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:32:10,634 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:32:10,693 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:32:10,752 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Update'}, 'finish_reason': None}]}
2025-04-20 20:32:10,807 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' File'}, 'finish_reason': None}]}
2025-04-20 20:32:10,864 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':'}, 'finish_reason': None}]}
2025-04-20 20:32:10,920 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' path'}, 'finish_reason': None}]}
2025-04-20 20:32:10,974 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181130, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '/to'}, 'finish_reason': None}]}
2025-04-20 20:32:11,028 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '/example'}, 'finish_reason': None}]}
2025-04-20 20:32:11,083 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.py'}, 'finish_reason': None}]}
2025-04-20 20:32:11,142 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:32:11,199 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@@'}, 'finish_reason': None}]}
2025-04-20 20:32:11,258 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:32:11,314 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '9'}, 'finish_reason': None}]}
2025-04-20 20:32:11,371 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:32:11,431 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '6'}, 'finish_reason': None}]}
2025-04-20 20:32:11,486 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' +'}, 'finish_reason': None}]}
2025-04-20 20:32:11,546 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '9'}, 'finish_reason': None}]}
2025-04-20 20:32:11,602 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:32:11,658 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '7'}, 'finish_reason': None}]}
2025-04-20 20:32:11,714 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' @@'}, 'finish_reason': None}]}
2025-04-20 20:32:11,776 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:32:11,830 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:32:11,885 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:32:11,947 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181131, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' def'}, 'finish_reason': None}]}
2025-04-20 20:32:12,003 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' example'}, 'finish_reason': None}]}
2025-04-20 20:32:12,065 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '():'}, 'finish_reason': None}]}
2025-04-20 20:32:12,120 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:32:12,171 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:32:12,227 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:32:12,291 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '  '}, 'finish_reason': None}]}
2025-04-20 20:32:12,350 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:32:12,405 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': " '"}, 'finish_reason': None}]}
2025-04-20 20:32:12,466 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'old'}, 'finish_reason': None}]}
2025-04-20 20:32:12,514 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' value'}, 'finish_reason': None}]}
2025-04-20 20:32:12,569 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'\\"}, 'finish_reason': None}]}
2025-04-20 20:32:12,622 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:32:12,677 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:32:12,730 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' print'}, 'finish_reason': None}]}
2025-04-20 20:32:12,785 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:32:12,842 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'before'}, 'finish_reason': None}]}
2025-04-20 20:32:12,898 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "')"}, 'finish_reason': None}]}
2025-04-20 20:32:12,955 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181132, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:32:13,015 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:32:13,074 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:32:13,132 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' if'}, 'finish_reason': None}]}
2025-04-20 20:32:13,189 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' True'}, 'finish_reason': None}]}
2025-04-20 20:32:13,247 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\\'}, 'finish_reason': None}]}
2025-04-20 20:32:13,305 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:32:13,365 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:32:13,422 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '    '}, 'finish_reason': None}]}
2025-04-20 20:32:13,480 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' pass'}, 'finish_reason': None}]}
2025-04-20 20:32:13,537 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:32:13,596 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+'}, 'finish_reason': None}]}
2025-04-20 20:32:13,656 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:32:13,715 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:32:13,776 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '123'}, 'finish_reason': None}]}
2025-04-20 20:32:13,836 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '",'}, 'finish_reason': None}]}
2025-04-20 20:32:13,895 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' "***'}, 'finish_reason': None}]}
2025-04-20 20:32:13,952 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181133, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' End'}, 'finish_reason': None}]}
2025-04-20 20:32:14,011 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181134, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:32:14,068 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181134, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '"]'}, 'finish_reason': None}]}
2025-04-20 20:32:14,126 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181134, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' }'}, 'finish_reason': None}]}
2025-04-20 20:32:14,177 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-974', 'object': 'chat.completion.chunk', 'created': 1745181134, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'stop'}]}
2025-04-20 20:32:14,178 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:32:14,178 - api_adapter_stream - INFO - Response completed with text: { "cmd": ["apply_patch", "*** Begin Patch\n*** Update File: path/to/example.py\n@@ -9,6 +9,7 @@\n- d...
2025-04-20 20:32:14,179 - api_adapter_stream - INFO - Received [DONE] message after 149 chunks
2025-04-20 20:32:49,755 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:32:49,904 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:32:50,680 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:32:50,680 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:32:50,680 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:32:50,681 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:32:50,681 - api_adapter_responses - INFO - =======================
2025-04-20 20:32:50,681 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:32:50,681 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:32:50,681 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:32:50,681 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:32:50,681 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:32:50,689 - api_adapter_responses - INFO - Tools: []
2025-04-20 20:32:50,879 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:32:50,880 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:32:50,880 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_f013ffa94308416db0be4e3cd99aa652; message_id msg_172f3bdc8f3544dc9bb5bede5fb8a771
2025-04-20 20:32:50,880 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_f013ffa94308416db0be4e3cd99aa652', object='response', created_at=1745181170, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:32:50,881 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_f013ffa94308416db0be4e3cd99aa652', object='response', created_at=1745181170, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:32:50,882 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181170, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'I'}, 'finish_reason': None}]}
2025-04-20 20:32:50,938 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181170, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' will'}, 'finish_reason': None}]}
2025-04-20 20:32:50,992 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181170, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' call'}, 'finish_reason': None}]}
2025-04-20 20:32:51,045 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' `'}, 'finish_reason': None}]}
2025-04-20 20:32:51,100 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:32:51,151 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:32:51,208 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '`'}, 'finish_reason': None}]}
2025-04-20 20:32:51,263 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' with'}, 'finish_reason': None}]}
2025-04-20 20:32:51,324 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' some'}, 'finish_reason': None}]}
2025-04-20 20:32:51,380 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' text'}, 'finish_reason': None}]}
2025-04-20 20:32:51,434 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' and'}, 'finish_reason': None}]}
2025-04-20 20:32:51,487 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' a'}, 'finish_reason': None}]}
2025-04-20 20:32:51,542 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' filename'}, 'finish_reason': None}]}
2025-04-20 20:32:51,593 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.\n\n'}, 'finish_reason': None}]}
2025-04-20 20:32:51,645 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '{"'}, 'finish_reason': None}]}
2025-04-20 20:32:51,700 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'cmd'}, 'finish_reason': None}]}
2025-04-20 20:32:51,750 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '":["'}, 'finish_reason': None}]}
2025-04-20 20:32:51,804 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:32:51,857 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:32:51,915 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '","'}, 'finish_reason': None}]}
2025-04-20 20:32:51,968 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181171, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:32:52,017 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Begin'}, 'finish_reason': None}]}
2025-04-20 20:32:52,068 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:32:52,122 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:32:52,175 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:32:52,230 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Update'}, 'finish_reason': None}]}
2025-04-20 20:32:52,281 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' File'}, 'finish_reason': None}]}
2025-04-20 20:32:52,332 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':'}, 'finish_reason': None}]}
2025-04-20 20:32:52,384 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' src'}, 'finish_reason': None}]}
2025-04-20 20:32:52,438 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '/main'}, 'finish_reason': None}]}
2025-04-20 20:32:52,490 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.py'}, 'finish_reason': None}]}
2025-04-20 20:32:52,543 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:32:52,598 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@@'}, 'finish_reason': None}]}
2025-04-20 20:32:52,639 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:32:52,693 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '10'}, 'finish_reason': None}]}
2025-04-20 20:32:52,753 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:32:52,817 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '7'}, 'finish_reason': None}]}
2025-04-20 20:32:52,877 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' +'}, 'finish_reason': None}]}
2025-04-20 20:32:52,935 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '10'}, 'finish_reason': None}]}
2025-04-20 20:32:52,992 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181172, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:32:53,060 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '7'}, 'finish_reason': None}]}
2025-04-20 20:32:53,117 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' @@\n'}, 'finish_reason': None}]}
2025-04-20 20:32:53,176 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '   '}, 'finish_reason': None}]}
2025-04-20 20:32:53,232 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' def'}, 'finish_reason': None}]}
2025-04-20 20:32:53,293 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' example'}, 'finish_reason': None}]}
2025-04-20 20:32:53,352 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '():\n'}, 'finish_reason': None}]}
2025-04-20 20:32:53,411 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '       '}, 'finish_reason': None}]}
2025-04-20 20:32:53,469 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' try'}, 'finish_reason': None}]}
2025-04-20 20:32:53,527 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\n'}, 'finish_reason': None}]}
2025-04-20 20:32:53,585 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:32:53,648 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '           '}, 'finish_reason': None}]}
2025-04-20 20:32:53,705 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' result'}, 'finish_reason': None}]}
2025-04-20 20:32:53,764 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' ='}, 'finish_reason': None}]}
2025-04-20 20:32:53,819 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:32:53,877 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '1'}, 'finish_reason': None}]}
2025-04-20 20:32:53,931 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' /'}, 'finish_reason': None}]}
2025-04-20 20:32:53,986 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181173, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:32:54,041 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '0'}, 'finish_reason': None}]}
2025-04-20 20:32:54,097 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\n'}, 'finish_reason': None}]}
2025-04-20 20:32:54,151 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+'}, 'finish_reason': None}]}
2025-04-20 20:32:54,210 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '           '}, 'finish_reason': None}]}
2025-04-20 20:32:54,268 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:32:54,325 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' "'}, 'finish_reason': None}]}
2025-04-20 20:32:54,378 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' division'}, 'finish_reason': None}]}
2025-04-20 20:32:54,430 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' by'}, 'finish_reason': None}]}
2025-04-20 20:32:54,486 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' zero'}, 'finish_reason': None}]}
2025-04-20 20:32:54,542 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '"\n'}, 'finish_reason': None}]}
2025-04-20 20:32:54,598 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '       '}, 'finish_reason': None}]}
2025-04-20 20:32:54,653 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' except'}, 'finish_reason': None}]}
2025-04-20 20:32:54,709 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Zero'}, 'finish_reason': None}]}
2025-04-20 20:32:54,767 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'Division'}, 'finish_reason': None}]}
2025-04-20 20:32:54,824 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'Error'}, 'finish_reason': None}]}
2025-04-20 20:32:54,891 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' as'}, 'finish_reason': None}]}
2025-04-20 20:32:54,953 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181174, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' e'}, 'finish_reason': None}]}
2025-04-20 20:32:55,009 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\n'}, 'finish_reason': None}]}
2025-04-20 20:32:55,068 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '           '}, 'finish_reason': None}]}
2025-04-20 20:32:55,123 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' print'}, 'finish_reason': None}]}
2025-04-20 20:32:55,181 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '(f'}, 'finish_reason': None}]}
2025-04-20 20:32:55,235 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '"'}, 'finish_reason': None}]}
2025-04-20 20:32:55,299 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'Exception'}, 'finish_reason': None}]}
2025-04-20 20:32:55,357 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' caught'}, 'finish_reason': None}]}
2025-04-20 20:32:55,421 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '...'}, 'finish_reason': None}]}
2025-04-20 20:32:55,485 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' {'}, 'finish_reason': None}]}
2025-04-20 20:32:55,540 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'e'}, 'finish_reason': None}]}
2025-04-20 20:32:55,604 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '}")\n'}, 'finish_reason': None}]}
2025-04-20 20:32:55,666 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '           '}, 'finish_reason': None}]}
2025-04-20 20:32:55,726 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:32:55,787 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': " '"}, 'finish_reason': None}]}
2025-04-20 20:32:55,855 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'exception'}, 'finish_reason': None}]}
2025-04-20 20:32:55,909 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'\n"}, 'finish_reason': None}]}
2025-04-20 20:32:55,969 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181175, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '***'}, 'finish_reason': None}]}
2025-04-20 20:32:56,023 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181176, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' End'}, 'finish_reason': None}]}
2025-04-20 20:32:56,081 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181176, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Patch'}, 'finish_reason': None}]}
2025-04-20 20:32:56,136 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181176, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '"]}'}, 'finish_reason': None}]}
2025-04-20 20:32:56,192 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-810', 'object': 'chat.completion.chunk', 'created': 1745181176, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'stop'}]}
2025-04-20 20:32:56,193 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:32:56,193 - api_adapter_stream - INFO - Response completed with text: I will call `apply_patch` with some text and a filename.

{"cmd":["apply_patch","*** Begin Patch\n**...
2025-04-20 20:32:56,193 - api_adapter_stream - INFO - Received [DONE] message after 191 chunks
2025-04-20 20:34:28,291 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:34:28,439 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:34:31,787 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:34:31,787 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:34:31,788 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:34:31,788 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:34:31,788 - api_adapter_responses - INFO - =======================
2025-04-20 20:34:31,788 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:34:31,789 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:34:31,789 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:34:31,789 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:34:31,789 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 0 tools
2025-04-20 20:34:31,790 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:34:31,802 - api_adapter_responses - INFO - Tools: []
2025-04-20 20:34:31,975 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:34:31,976 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:34:31,976 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_fdac03705aa44aa18beead8c95959e1a; message_id msg_4d10f4388c1c40a69ac13f5fb368f3ad
2025-04-20 20:34:31,976 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_fdac03705aa44aa18beead8c95959e1a', object='response', created_at=1745181271, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:34:31,978 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_fdac03705aa44aa18beead8c95959e1a', object='response', created_at=1745181271, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:34:31,979 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181271, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'Apply'}, 'finish_reason': None}]}
2025-04-20 20:34:32,030 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:34:32,085 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ':\n'}, 'finish_reason': None}]}
2025-04-20 20:34:32,139 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '{"'}, 'finish_reason': None}]}
2025-04-20 20:34:32,193 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'cmd'}, 'finish_reason': None}]}
2025-04-20 20:34:32,243 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '":["'}, 'finish_reason': None}]}
2025-04-20 20:34:32,293 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'apply'}, 'finish_reason': None}]}
2025-04-20 20:34:32,344 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:34:32,402 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '","'}, 'finish_reason': None}]}
2025-04-20 20:34:32,456 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@@'}, 'finish_reason': None}]}
2025-04-20 20:34:32,509 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:34:32,563 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '1'}, 'finish_reason': None}]}
2025-04-20 20:34:32,616 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:34:32,673 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '4'}, 'finish_reason': None}]}
2025-04-20 20:34:32,727 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' +'}, 'finish_reason': None}]}
2025-04-20 20:34:32,780 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:34:32,832 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '1'}, 'finish_reason': None}]}
2025-04-20 20:34:32,893 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:34:32,947 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181272, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '13'}, 'finish_reason': None}]}
2025-04-20 20:34:33,001 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' @'}, 'finish_reason': None}]}
2025-04-20 20:34:33,057 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@'}, 'finish_reason': None}]}
2025-04-20 20:34:33,109 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:34:33,165 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'console'}, 'finish_reason': None}]}
2025-04-20 20:34:33,224 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.log'}, 'finish_reason': None}]}
2025-04-20 20:34:33,281 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:34:33,339 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'hello'}, 'finish_reason': None}]}
2025-04-20 20:34:33,397 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "')"}, 'finish_reason': None}]}
2025-04-20 20:34:33,452 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:34:33,505 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:33,559 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}, 'finish_reason': None}]}
2025-04-20 20:34:33,603 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' console'}, 'finish_reason': None}]}
2025-04-20 20:34:33,651 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.log'}, 'finish_reason': None}]}
2025-04-20 20:34:33,704 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:34:33,757 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'world'}, 'finish_reason': None}]}
2025-04-20 20:34:33,817 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "')"}, 'finish_reason': None}]}
2025-04-20 20:34:33,871 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:34:33,931 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:33,986 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181273, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+'}, 'finish_reason': None}]}
2025-04-20 20:34:34,039 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:34:34,094 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': " '"}, 'finish_reason': None}]}
2025-04-20 20:34:34,152 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'good'}, 'finish_reason': None}]}
2025-04-20 20:34:34,205 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'bye'}, 'finish_reason': None}]}
2025-04-20 20:34:34,260 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'\\"}, 'finish_reason': None}]}
2025-04-20 20:34:34,316 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'ndef'}, 'finish_reason': None}]}
2025-04-20 20:34:34,370 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' main'}, 'finish_reason': None}]}
2025-04-20 20:34:34,431 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '():'}, 'finish_reason': None}]}
2025-04-20 20:34:34,487 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:34:34,545 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:34,600 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:34,654 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'return'}, 'finish_reason': None}]}
2025-04-20 20:34:34,708 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:34:34,764 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:34,819 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'print'}, 'finish_reason': None}]}
2025-04-20 20:34:34,875 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:34:34,931 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'example'}, 'finish_reason': None}]}
2025-04-20 20:34:34,991 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181274, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'\\"}, 'finish_reason': None}]}
2025-04-20 20:34:35,049 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:35,105 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:35,165 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:35,227 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ")'"}, 'finish_reason': None}]}
2025-04-20 20:34:35,284 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '"]\n\n'}, 'finish_reason': None}]}
2025-04-20 20:34:35,343 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'Running'}, 'finish_reason': None}]}
2025-04-20 20:34:35,396 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' apply'}, 'finish_reason': None}]}
2025-04-20 20:34:35,450 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '_patch'}, 'finish_reason': None}]}
2025-04-20 20:34:35,509 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' with'}, 'finish_reason': None}]}
2025-04-20 20:34:35,565 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' file'}, 'finish_reason': None}]}
2025-04-20 20:34:35,619 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' path'}, 'finish_reason': None}]}
2025-04-20 20:34:35,676 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': " '@"}, 'finish_reason': None}]}
2025-04-20 20:34:35,727 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '@'}, 'finish_reason': None}]}
2025-04-20 20:34:35,780 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:34:35,836 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '1'}, 'finish_reason': None}]}
2025-04-20 20:34:35,893 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:34:35,953 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181275, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '4'}, 'finish_reason': None}]}
2025-04-20 20:34:36,007 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' +'}, 'finish_reason': None}]}
2025-04-20 20:34:36,063 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}, 'finish_reason': None}]}
2025-04-20 20:34:36,113 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '1'}, 'finish_reason': None}]}
2025-04-20 20:34:36,162 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ','}, 'finish_reason': None}]}
2025-04-20 20:34:36,218 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '13'}, 'finish_reason': None}]}
2025-04-20 20:34:36,273 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' @@'}, 'finish_reason': None}]}
2025-04-20 20:34:36,329 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' -'}, 'finish_reason': None}]}
2025-04-20 20:34:36,384 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'console'}, 'finish_reason': None}]}
2025-04-20 20:34:36,440 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.log'}, 'finish_reason': None}]}
2025-04-20 20:34:36,495 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:34:36,553 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'hello'}, 'finish_reason': None}]}
2025-04-20 20:34:36,612 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "')"}, 'finish_reason': None}]}
2025-04-20 20:34:36,663 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:34:36,719 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:36,774 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'-"}, 'finish_reason': None}]}
2025-04-20 20:34:36,832 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' console'}, 'finish_reason': None}]}
2025-04-20 20:34:36,888 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.log'}, 'finish_reason': None}]}
2025-04-20 20:34:36,945 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:34:37,000 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181276, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'world'}, 'finish_reason': None}]}
2025-04-20 20:34:37,054 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "')"}, 'finish_reason': None}]}
2025-04-20 20:34:37,111 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:34:37,166 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:37,223 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '+'}, 'finish_reason': None}]}
2025-04-20 20:34:37,283 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' return'}, 'finish_reason': None}]}
2025-04-20 20:34:37,337 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': " '"}, 'finish_reason': None}]}
2025-04-20 20:34:37,395 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'good'}, 'finish_reason': None}]}
2025-04-20 20:34:37,450 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'bye'}, 'finish_reason': None}]}
2025-04-20 20:34:37,503 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'\\"}, 'finish_reason': None}]}
2025-04-20 20:34:37,556 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'ndef'}, 'finish_reason': None}]}
2025-04-20 20:34:37,611 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' main'}, 'finish_reason': None}]}
2025-04-20 20:34:37,666 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '():'}, 'finish_reason': None}]}
2025-04-20 20:34:37,724 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\'}, 'finish_reason': None}]}
2025-04-20 20:34:37,778 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:37,839 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:37,896 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'return'}, 'finish_reason': None}]}
2025-04-20 20:34:37,951 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181277, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\n'}, 'finish_reason': None}]}
2025-04-20 20:34:38,006 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:38,067 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'print'}, 'finish_reason': None}]}
2025-04-20 20:34:38,121 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "('"}, 'finish_reason': None}]}
2025-04-20 20:34:38,178 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'example'}, 'finish_reason': None}]}
2025-04-20 20:34:38,233 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'\\"}, 'finish_reason': None}]}
2025-04-20 20:34:38,286 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'n'}, 'finish_reason': None}]}
2025-04-20 20:34:38,341 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:38,401 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '\\t'}, 'finish_reason': None}]}
2025-04-20 20:34:38,459 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ')'}, 'finish_reason': None}]}
2025-04-20 20:34:38,517 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': "'."}, 'finish_reason': None}]}
2025-04-20 20:34:38,573 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' The'}, 'finish_reason': None}]}
2025-04-20 20:34:38,628 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' file'}, 'finish_reason': None}]}
2025-04-20 20:34:38,679 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' has'}, 'finish_reason': None}]}
2025-04-20 20:34:38,737 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' been'}, 'finish_reason': None}]}
2025-04-20 20:34:38,800 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' updated'}, 'finish_reason': None}]}
2025-04-20 20:34:38,856 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '.'}, 'finish_reason': None}]}
2025-04-20 20:34:38,921 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-781', 'object': 'chat.completion.chunk', 'created': 1745181278, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'stop'}]}
2025-04-20 20:34:38,922 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:34:38,922 - api_adapter_stream - INFO - Response completed with text: Apply_patch:
{"cmd":["apply_patch","@@ -1,4 + 1,13 @@ -console.log('hello')\n- console.log('world')\...
2025-04-20 20:34:38,922 - api_adapter_stream - INFO - Received [DONE] message after 253 chunks
2025-04-20 20:36:31,989 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:36:32,138 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:36:44,436 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:36:44,585 - api_adapter - INFO - Configuration: OPENAI_BASE_URL_INTERNAL=http://localhost:8000, API_PORT=8080
2025-04-20 20:36:54,630 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:36:54,630 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:36:54,631 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:36:54,631 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename
2025-04-20 20:36:54,631 - api_adapter_responses - INFO - =======================
2025-04-20 20:36:54,631 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:36:54,632 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:36:54,632 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename'}], 'type': 'message'}]
2025-04-20 20:36:54,632 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename...
2025-04-20 20:36:54,632 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:36:54,632 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:36:54,632 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:36:54,644 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:36:58,455 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:36:58,455 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:36:58,456 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_300f1fcba9c146c6b5df9cb3c8d02811; message_id msg_c29759551cf148f0a61c57c2aeda4f23
2025-04-20 20:36:58,456 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_300f1fcba9c146c6b5df9cb3c8d02811', object='response', created_at=1745181418, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:36:58,457 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_300f1fcba9c146c6b5df9cb3c8d02811', object='response', created_at=1745181418, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:36:58,459 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-589', 'object': 'chat.completion.chunk', 'created': 1745181418, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_8g8phjfs', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":"[\\"apply_patch\\", \\"*** Begin Patch\\\\n*** Update File: path/to/file.py\\\\n@@ def example():\\\\n-  pass\\\\n+  return 123\\\\n*** End Patch\\"]"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:36:58,459 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_8g8phjfs', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":"[\\"apply_patch\\", \\"*** Begin Patch\\\\n*** Update File: path/to/file.py\\\\n@@ def example():\\\\n-  pass\\\\n+  return 123\\\\n*** End Patch\\"]"}'}}]}
2025-04-20 20:36:58,460 - api_adapter_stream - INFO - Tool call created: apply_patch
2025-04-20 20:36:58,506 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-589', 'object': 'chat.completion.chunk', 'created': 1745181418, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:36:58,507 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:36:58,507 - api_adapter_stream - INFO - Tool call completed: apply_patch with arguments: {"cmd":"[\"apply_patch\", \"*** Begin Patch\\n*** Update File: path/to/file.py\\n@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch\"]"}
2025-04-20 20:36:58,507 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:38:04,385 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:38:04,386 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:38:04,386 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:38:04,386 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename, path:
2025-04-20 20:38:04,386 - api_adapter_responses - INFO - =======================
2025-04-20 20:38:04,387 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:38:04,387 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:38:04,387 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename, path:'}], 'type': 'message'}]
2025-04-20 20:38:04,387 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename, path:...
2025-04-20 20:38:04,387 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:38:04,388 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:38:04,388 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:38:04,389 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:38:07,953 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:38:07,954 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:38:07,954 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_9be66cd02154489f8a78900c8ee19fc3; message_id msg_09ec3e1a43e5477e838b461b9a07a3af
2025-04-20 20:38:07,955 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_9be66cd02154489f8a78900c8ee19fc3', object='response', created_at=1745181487, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:07,956 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_9be66cd02154489f8a78900c8ee19fc3', object='response', created_at=1745181487, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:07,957 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-318', 'object': 'chat.completion.chunk', 'created': 1745181487, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_ffms2rk7', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":"[\\"apply_patch\\",\\"*** Begin Patch\\\\n*** Update File: path/to/file.py\\\\n@@ def example():\\\\n-  pass\\\\n+  return 123\\\\n*** End Patch\\"]"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:38:07,958 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_ffms2rk7', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":"[\\"apply_patch\\",\\"*** Begin Patch\\\\n*** Update File: path/to/file.py\\\\n@@ def example():\\\\n-  pass\\\\n+  return 123\\\\n*** End Patch\\"]"}'}}]}
2025-04-20 20:38:07,958 - api_adapter_stream - INFO - Tool call created: apply_patch
2025-04-20 20:38:08,011 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-318', 'object': 'chat.completion.chunk', 'created': 1745181488, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:38:08,012 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:38:08,012 - api_adapter_stream - INFO - Tool call completed: apply_patch with arguments: {"cmd":"[\"apply_patch\",\"*** Begin Patch\\n*** Update File: path/to/file.py\\n@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch\"]"}
2025-04-20 20:38:08,013 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:38:14,169 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:38:14,169 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:38:14,170 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:38:14,170 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename, path: /2.2
2025-04-20 20:38:14,170 - api_adapter_responses - INFO - =======================
2025-04-20 20:38:14,170 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:38:14,171 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:38:14,171 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename, path: /2.2'}], 'type': 'message'}]
2025-04-20 20:38:14,171 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename, path: /2.2...
2025-04-20 20:38:14,172 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:38:14,172 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:38:14,172 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:38:14,174 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:38:17,805 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:38:17,805 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:38:17,806 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_5bbb886aff2443389bda7b85a360c922; message_id msg_d747075055b14197a221ff1eed55f090
2025-04-20 20:38:17,806 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_5bbb886aff2443389bda7b85a360c922', object='response', created_at=1745181497, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:17,807 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_5bbb886aff2443389bda7b85a360c922', object='response', created_at=1745181497, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:17,808 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-799', 'object': 'chat.completion.chunk', 'created': 1745181497, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '{"name": "apply_patch", "parameters": {"cmd": "[\\"apply_patch\\", \\"*** Begin Patch\\n*** Update File: \\_2.2.py\\n@@ def example():\\n-  pass\\\\n+  return 123\\\\n*** End Patch\\"]"}}'}, 'finish_reason': 'stop'}]}
2025-04-20 20:38:17,808 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:38:17,809 - api_adapter_stream - INFO - Response completed with text: {"name": "apply_patch", "parameters": {"cmd": "[\"apply_patch\", \"*** Begin Patch\n*** Update File:...
2025-04-20 20:38:17,809 - api_adapter_stream - INFO - Received [DONE] message after 3 chunks
2025-04-20 20:38:26,017 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:38:26,017 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:38:26,018 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:38:26,018 - api_adapter_responses - INFO - USER INPUT: this is a test, just call apply patch with some text and filename: /2.2
2025-04-20 20:38:26,018 - api_adapter_responses - INFO - =======================
2025-04-20 20:38:26,018 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:38:26,018 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:38:26,019 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, just call apply patch with some text and filename: /2.2'}], 'type': 'message'}]
2025-04-20 20:38:26,019 - api_adapter_conversion - INFO - User message: this is a test, just call apply patch with some text and filename: /2.2...
2025-04-20 20:38:26,019 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:38:26,019 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:38:26,019 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:38:26,021 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:38:28,897 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:38:28,897 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:38:28,898 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_5d94349ad4914b09b97b75e909778083; message_id msg_5850e9cc091f4f38afe75e748b85dfd0
2025-04-20 20:38:28,898 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_5d94349ad4914b09b97b75e909778083', object='response', created_at=1745181508, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:28,899 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_5d94349ad4914b09b97b75e909778083', object='response', created_at=1745181508, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:28,900 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-544', 'object': 'chat.completion.chunk', 'created': 1745181508, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_7ikcf1hl', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":["apply_patch","*** Begin Patch","*** Update File:/2.2","@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch"]}'}}]}, 'finish_reason': None}]}
2025-04-20 20:38:28,900 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_7ikcf1hl', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":["apply_patch","*** Begin Patch","*** Update File:/2.2","@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch"]}'}}]}
2025-04-20 20:38:28,900 - api_adapter_stream - INFO - Tool call created: apply_patch
2025-04-20 20:38:28,953 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-544', 'object': 'chat.completion.chunk', 'created': 1745181508, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:38:28,953 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:38:28,954 - api_adapter_stream - INFO - Tool call completed: apply_patch with arguments: {"cmd":["apply_patch","*** Begin Patch","*** Update File:/2.2","@@ def example():\n-  pass\n+  return 123\n*** End Patch"]}
2025-04-20 20:38:28,954 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:38:49,652 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:38:49,652 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:38:49,652 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:38:49,652 - api_adapter_responses - INFO - USER INPUT: this is a test, create a new file. just call apply patch with some text and filename: /2.2
2025-04-20 20:38:49,652 - api_adapter_responses - INFO - =======================
2025-04-20 20:38:49,652 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:38:49,653 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:38:49,653 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, create a new file. just call apply patch with some text and filename: /2.2'}], 'type': 'message'}]
2025-04-20 20:38:49,653 - api_adapter_conversion - INFO - User message: this is a test, create a new file. just call apply patch with some text and filename: /2.2...
2025-04-20 20:38:49,653 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:38:49,653 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:38:49,653 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:38:49,654 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:38:51,057 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:38:51,057 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:38:51,057 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_806e31c14eec41928e3ddaf36a4bf13c; message_id msg_dd0c66c782df4ff091468c5263b7d5a9
2025-04-20 20:38:51,057 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_806e31c14eec41928e3ddaf36a4bf13c', object='response', created_at=1745181531, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:51,058 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_806e31c14eec41928e3ddaf36a4bf13c', object='response', created_at=1745181531, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:38:51,060 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-918', 'object': 'chat.completion.chunk', 'created': 1745181531, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_qe76gzcj', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"$":"{","f":"/2.2"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:38:51,060 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_qe76gzcj', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"$":"{","f":"/2.2"}'}}]}
2025-04-20 20:38:51,061 - api_adapter_stream - INFO - Tool call created: apply_patch
2025-04-20 20:38:51,116 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-918', 'object': 'chat.completion.chunk', 'created': 1745181531, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:38:51,117 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:38:51,117 - api_adapter_stream - INFO - Tool call completed: apply_patch with arguments: {"$":"{","f":"/2.2"}
2025-04-20 20:38:51,118 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:39:00,640 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:39:00,641 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:39:00,641 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:39:00,641 - api_adapter_responses - INFO - USER INPUT: this is a test, create a new file with content test. just call apply patch with some text and filename: /2.2
2025-04-20 20:39:00,641 - api_adapter_responses - INFO - =======================
2025-04-20 20:39:00,641 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:39:00,641 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:39:00,642 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, create a new file with content test. just call apply patch with some text and filename: /2.2'}], 'type': 'message'}]
2025-04-20 20:39:00,642 - api_adapter_conversion - INFO - User message: this is a test, create a new file with content test. just call apply patch with some text and filena...
2025-04-20 20:39:00,642 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:39:00,642 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:39:00,642 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:39:00,643 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:39:06,002 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:39:06,002 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:39:06,003 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_754c51f052c741c1b530e506d73e8d98; message_id msg_9cb9ad20415042eb83dc94fea7d30d99
2025-04-20 20:39:06,003 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_754c51f052c741c1b530e506d73e8d98', object='response', created_at=1745181546, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:39:06,003 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_754c51f052c741c1b530e506d73e8d98', object='response', created_at=1745181546, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:39:06,004 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-206', 'object': 'chat.completion.chunk', 'created': 1745181546, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '{"name": "apply_patch", "parameters": {"patch": "[{\\"cmd\\":[\\"apply_patch\\",\\" Begin Patch\\n/2.2\\",\\n{\\n  \\"path\\":\\"test.py\\"\\n,\\n  \\"@@ -1 +1 @@\\"\\n,\\n  \\"- def example():\\\\n+\\n+  return 123\\\\n-",\\n"\\n+ def example():\\\\n  return 123\\n"},\\"End Patch\\"]"}}'}, 'finish_reason': 'stop'}]}
2025-04-20 20:39:06,004 - api_adapter_stream - INFO - Received finish_reason: stop
2025-04-20 20:39:06,005 - api_adapter_stream - INFO - Response completed with text: {"name": "apply_patch", "parameters": {"patch": "[{\"cmd\":[\"apply_patch\",\" Begin Patch\n/2.2\",\...
2025-04-20 20:39:06,005 - api_adapter_stream - INFO - Received [DONE] message after 3 chunks
2025-04-20 20:39:14,869 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:39:14,870 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:39:14,870 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:39:14,870 - api_adapter_responses - INFO - USER INPUT: this is a test, create a new file with content test. just call apply patch with some text and filename: /2.2
2025-04-20 20:39:14,870 - api_adapter_responses - INFO - =======================
2025-04-20 20:39:14,870 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:39:14,870 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:39:14,871 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'this is a test, create a new file with content test. just call apply patch with some text and filename: /2.2'}], 'type': 'message'}]
2025-04-20 20:39:14,871 - api_adapter_conversion - INFO - User message: this is a test, create a new file with content test. just call apply patch with some text and filena...
2025-04-20 20:39:14,871 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:39:14,871 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:39:14,871 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:39:14,872 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:39:19,352 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:39:19,353 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:39:19,353 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_7645241e539042d1b8f760f096cde070; message_id msg_204d2a4b407a40169d15f7be72d74ca0
2025-04-20 20:39:19,353 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_7645241e539042d1b8f760f096cde070', object='response', created_at=1745181559, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:39:19,354 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_7645241e539042d1b8f760f096cde070', object='response', created_at=1745181559, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:39:19,355 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-404', 'object': 'chat.completion.chunk', 'created': 1745181559, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_q8xqcu28', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":"[\\"apply_patch\\", \\"** Begin Patch \\\\n\\\\t  * Create file: test.py\\n\\\\n@@ -1,0 +1,0 @@\\\\n- # Python 3.x compatibility layer\\\\n+ # Created by Codex CLI for test purposes\\\\n\\\\n*** End Patch\\"]"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:39:19,355 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_q8xqcu28', 'index': 0, 'type': 'function', 'function': {'name': 'apply_patch', 'arguments': '{"cmd":"[\\"apply_patch\\", \\"** Begin Patch \\\\n\\\\t  * Create file: test.py\\n\\\\n@@ -1,0 +1,0 @@\\\\n- # Python 3.x compatibility layer\\\\n+ # Created by Codex CLI for test purposes\\\\n\\\\n*** End Patch\\"]"}'}}]}
2025-04-20 20:39:19,355 - api_adapter_stream - INFO - Tool call created: apply_patch
2025-04-20 20:39:19,408 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-404', 'object': 'chat.completion.chunk', 'created': 1745181559, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:39:19,408 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:39:19,408 - api_adapter_stream - INFO - Tool call completed: apply_patch with arguments: {"cmd":"[\"apply_patch\", \"** Begin Patch \\n\\t  * Create file: test.py\n\\n@@ -1,0 +1,0 @@\\n- # Python 3.x compatibility layer\\n+ # Created by Codex CLI for test purposes\\n\\n*** End Patch\"]"}
2025-04-20 20:39:19,409 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:41:12,225 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:41:12,226 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:41:12,226 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:41:12,226 - api_adapter_responses - INFO - USER INPUT: list files with 'shell' command
2025-04-20 20:41:12,226 - api_adapter_responses - INFO - =======================
2025-04-20 20:41:12,226 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:41:12,227 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:41:12,227 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': "list files with 'shell' command"}], 'type': 'message'}]
2025-04-20 20:41:12,227 - api_adapter_conversion - INFO - User message: list files with 'shell' command...
2025-04-20 20:41:12,227 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:41:12,227 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:41:12,228 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:41:12,229 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:41:13,406 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:41:13,407 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:41:13,407 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_72d1018ec09244ae83a5c9e7f84db5b8; message_id msg_f3ecc5f5b50e43a7b15d7a42e2ceb35c
2025-04-20 20:41:13,407 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_72d1018ec09244ae83a5c9e7f84db5b8', object='response', created_at=1745181673, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:41:13,408 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_72d1018ec09244ae83a5c9e7f84db5b8', object='response', created_at=1745181673, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:41:13,410 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-689', 'object': 'chat.completion.chunk', 'created': 1745181673, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_soczn0uu', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls"]}'}}]}, 'finish_reason': None}]}
2025-04-20 20:41:13,410 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_soczn0uu', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls"]}'}}]}
2025-04-20 20:41:13,410 - api_adapter_stream - INFO - Tool call created: shell
2025-04-20 20:41:13,464 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-689', 'object': 'chat.completion.chunk', 'created': 1745181673, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:41:13,465 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:41:13,465 - api_adapter_stream - INFO - Tool call completed: shell with arguments: {"command":["ls"]}
2025-04-20 20:41:13,466 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:41:36,555 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:41:36,555 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:41:36,556 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:41:36,556 - api_adapter_responses - INFO - USER INPUT: ls / folder
2025-04-20 20:41:36,556 - api_adapter_responses - INFO - =======================
2025-04-20 20:41:36,556 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:41:36,557 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:41:36,557 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'ls / folder'}], 'type': 'message'}]
2025-04-20 20:41:36,558 - api_adapter_conversion - INFO - User message: ls / folder...
2025-04-20 20:41:36,558 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:41:36,558 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:41:36,559 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:41:36,560 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:41:38,601 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:41:38,602 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:41:38,602 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_a04acef8ad3943ac804c1622011378e3; message_id msg_bdc92f41a9db41f18e9c92d45b1bcdf9
2025-04-20 20:41:38,603 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_a04acef8ad3943ac804c1622011378e3', object='response', created_at=1745181698, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:41:38,604 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_a04acef8ad3943ac804c1622011378e3', object='response', created_at=1745181698, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:41:38,606 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-955', 'object': 'chat.completion.chunk', 'created': 1745181698, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_9cbzjydn', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls","/folder"],"timeout":60000,"workdir":"/"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:41:38,606 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_9cbzjydn', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls","/folder"],"timeout":60000,"workdir":"/"}'}}]}
2025-04-20 20:41:38,606 - api_adapter_stream - INFO - Tool call created: shell
2025-04-20 20:41:38,659 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-955', 'object': 'chat.completion.chunk', 'created': 1745181698, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:41:38,660 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:41:38,660 - api_adapter_stream - INFO - Tool call completed: shell with arguments: {"command":["ls","/folder"],"timeout":60000,"workdir":"/"}
2025-04-20 20:41:38,661 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:41:56,999 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:41:57,000 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:41:57,000 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:41:57,000 - api_adapter_responses - INFO - USER INPUT: ls root folder
2025-04-20 20:41:57,000 - api_adapter_responses - INFO - =======================
2025-04-20 20:41:57,001 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:41:57,001 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:41:57,001 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'ls root folder'}], 'type': 'message'}]
2025-04-20 20:41:57,001 - api_adapter_conversion - INFO - User message: ls root folder...
2025-04-20 20:41:57,001 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:41:57,001 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:41:57,001 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:41:57,003 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:41:58,696 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:41:58,696 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:41:58,696 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_19723d113fba453087088ba6e46e14fd; message_id msg_c41743d7617f4e72b737d061ad73f202
2025-04-20 20:41:58,697 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_19723d113fba453087088ba6e46e14fd', object='response', created_at=1745181718, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:41:58,697 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_19723d113fba453087088ba6e46e14fd', object='response', created_at=1745181718, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:41:58,699 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-536', 'object': 'chat.completion.chunk', 'created': 1745181718, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_g0a68bho', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls","-l"],"workdir":"root"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:41:58,700 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_g0a68bho', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls","-l"],"workdir":"root"}'}}]}
2025-04-20 20:41:58,700 - api_adapter_stream - INFO - Tool call created: shell
2025-04-20 20:41:58,756 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-536', 'object': 'chat.completion.chunk', 'created': 1745181718, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:41:58,757 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:41:58,757 - api_adapter_stream - INFO - Tool call completed: shell with arguments: {"command":["ls","-l"],"workdir":"root"}
2025-04-20 20:41:58,757 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:42:38,980 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:42:38,981 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:42:38,981 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:42:38,981 - api_adapter_responses - INFO - USER INPUT: run command echo "1.1" > 2.2 with shell tool
2025-04-20 20:42:38,981 - api_adapter_responses - INFO - =======================
2025-04-20 20:42:38,982 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:42:38,982 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:42:38,982 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'run command echo "1.1" > 2.2 with shell tool'}], 'type': 'message'}]
2025-04-20 20:42:38,982 - api_adapter_conversion - INFO - User message: run command echo "1.1" > 2.2 with shell tool...
2025-04-20 20:42:38,982 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:42:38,982 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:42:38,982 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:42:38,983 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:42:40,951 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:42:40,952 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:42:40,952 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_271deff9d87f42d5b5cf13286fb98c32; message_id msg_d26f696d1969452eb9eb5b0b81df8459
2025-04-20 20:42:40,952 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_271deff9d87f42d5b5cf13286fb98c32', object='response', created_at=1745181760, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:42:40,953 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_271deff9d87f42d5b5cf13286fb98c32', object='response', created_at=1745181760, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:42:40,954 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-28', 'object': 'chat.completion.chunk', 'created': 1745181760, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_pj1h8o9c', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["echo","1.1"],"timeout":null,"workdir":"./"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:42:40,954 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_pj1h8o9c', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["echo","1.1"],"timeout":null,"workdir":"./"}'}}]}
2025-04-20 20:42:40,954 - api_adapter_stream - INFO - Tool call created: shell
2025-04-20 20:42:41,010 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-28', 'object': 'chat.completion.chunk', 'created': 1745181761, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:42:41,011 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:42:41,011 - api_adapter_stream - INFO - Tool call completed: shell with arguments: {"command":["echo","1.1"],"timeout":null,"workdir":"./"}
2025-04-20 20:42:41,012 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:43:27,942 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:43:27,943 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:43:27,943 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:43:27,943 - api_adapter_responses - INFO - USER INPUT: create a file with 1.1 using echo of 1.1 then the > sign and 2.2. Use that with 'shell' tool to create the file 2.2
2025-04-20 20:43:27,944 - api_adapter_responses - INFO - =======================
2025-04-20 20:43:27,944 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:43:27,944 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:43:27,944 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': "create a file with 1.1 using echo of 1.1 then the > sign and 2.2. Use that with 'shell' tool to create the file 2.2"}], 'type': 'message'}]
2025-04-20 20:43:27,944 - api_adapter_conversion - INFO - User message: create a file with 1.1 using echo of 1.1 then the > sign and 2.2. Use that with 'shell' tool to crea...
2025-04-20 20:43:27,944 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:43:27,944 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:43:27,944 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:43:27,945 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:43:29,781 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:43:29,782 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:43:29,782 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_7d23df3b51224319bbc57075fcfc7245; message_id msg_1272a06010d34388b0ba13a1914dde30
2025-04-20 20:43:29,783 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_7d23df3b51224319bbc57075fcfc7245', object='response', created_at=1745181809, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:43:29,783 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_7d23df3b51224319bbc57075fcfc7245', object='response', created_at=1745181809, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:43:29,784 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-37', 'object': 'chat.completion.chunk', 'created': 1745181809, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_d1wcsfnv', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["echo","1.1","\\u003e=","2.2"]}'}}]}, 'finish_reason': None}]}
2025-04-20 20:43:29,785 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_d1wcsfnv', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["echo","1.1","\\u003e=","2.2"]}'}}]}
2025-04-20 20:43:29,785 - api_adapter_stream - INFO - Tool call created: shell
2025-04-20 20:43:29,847 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-37', 'object': 'chat.completion.chunk', 'created': 1745181809, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:43:29,848 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:43:29,848 - api_adapter_stream - INFO - Tool call completed: shell with arguments: {"command":["echo","1.1","\u003e=","2.2"]}
2025-04-20 20:43:29,848 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
2025-04-20 20:43:52,274 - api_adapter_responses - INFO - Received request to /responses
2025-04-20 20:43:52,275 - api_adapter_responses - INFO - Received request: model=llama3.2:latest, stream=True
2025-04-20 20:43:52,275 - api_adapter_responses - INFO - ==== REQUEST CONTENT ====
2025-04-20 20:43:52,275 - api_adapter_responses - INFO - USER INPUT: now list the file you just created
2025-04-20 20:43:52,275 - api_adapter_responses - INFO - =======================
2025-04-20 20:43:52,276 - api_adapter_conversion - INFO - Request: model=llama3.2:latest, tools=1, has_instructions=True
2025-04-20 20:43:52,276 - api_adapter_conversion - INFO - tools=[{'type': 'function', 'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'strict': False, 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}]
2025-04-20 20:43:52,276 - api_adapter_conversion - INFO - Processing input messages [{'role': 'user', 'content': [{'type': 'input_text', 'text': 'now list the file you just created'}], 'type': 'message'}]
2025-04-20 20:43:52,276 - api_adapter_conversion - INFO - User message: now list the file you just created...
2025-04-20 20:43:52,276 - api_adapter_conversion - INFO - Tool 0: shell
2025-04-20 20:43:52,276 - api_adapter_conversion - INFO - Converted to chat completions: 2 messages, 1 tools
2025-04-20 20:43:52,277 - api_adapter_responses - INFO - Handling streaming response
2025-04-20 20:43:52,278 - api_adapter_responses - INFO - Tools: [{'type': 'function', 'function': {'name': 'shell', 'description': 'Runs a shell command, and returns its output.', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'array', 'items': {'type': 'string'}}, 'workdir': {'type': 'string', 'description': 'The working directory for the command.'}, 'timeout': {'type': 'number', 'description': 'The maximum time to wait for the command to complete in milliseconds.'}}, 'required': ['command'], 'additionalProperties': False}}}]
2025-04-20 20:43:54,124 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-20 20:43:54,125 - api_adapter_responses - INFO - Stream request status: 200
2025-04-20 20:43:54,125 - api_adapter_stream - INFO - Processing streaming response from chat.completions API response_id resp_a4e16dac20e84dc28aaeeb4ec76da202; message_id msg_f2e52d70e2f04d8d892def23d77f0c1e
2025-04-20 20:43:54,125 - api_adapter_stream - INFO - Emitting type='response.created' response=ResponseModel(id='resp_a4e16dac20e84dc28aaeeb4ec76da202', object='response', created_at=1745181834, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:43:54,126 - api_adapter_stream - INFO - Emitting type='response.in_progress' response=ResponseModel(id='resp_a4e16dac20e84dc28aaeeb4ec76da202', object='response', created_at=1745181834, status='in_progress', error=None, incomplete_details=None, instructions=None, max_output_tokens=None, model='', output=[], parallel_tool_calls=True, previous_response_id=None, reasoning={'effort': None, 'summary': None}, store=False, temperature=1.0, text={'format': {'type': 'text'}}, tool_choice='auto', tools=[], top_p=1.0, truncation='disabled', usage=None, user=None, metadata={})
2025-04-20 20:43:54,128 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-831', 'object': 'chat.completion.chunk', 'created': 1745181834, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_8r5342vx', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls"],"timeout":null,"workdir":"null"}'}}]}, 'finish_reason': None}]}
2025-04-20 20:43:54,128 - api_adapter_stream - INFO - tool_calls in {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_8r5342vx', 'index': 0, 'type': 'function', 'function': {'name': 'shell', 'arguments': '{"command":["ls"],"timeout":null,"workdir":"null"}'}}]}
2025-04-20 20:43:54,128 - api_adapter_stream - INFO - Tool call created: shell
2025-04-20 20:43:54,180 - api_adapter_stream - INFO - data: {'id': 'chatcmpl-831', 'object': 'chat.completion.chunk', 'created': 1745181834, 'model': 'llama3.2:latest', 'system_fingerprint': 'fp_ollama', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': 'tool_calls'}]}
2025-04-20 20:43:54,181 - api_adapter_stream - INFO - Received finish_reason: tool_calls
2025-04-20 20:43:54,182 - api_adapter_stream - INFO - Tool call completed: shell with arguments: {"command":["ls"],"timeout":null,"workdir":"null"}
2025-04-20 20:43:54,182 - api_adapter_stream - INFO - Received [DONE] message after 5 chunks
